% !Rnw root = 000proyecto.Rnw

<<echo=FALSE>>=
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(gridExtra)
@


\section{Redes Neuronales}

\subsection{Modelo biológico}
Como explican los autores en \cite{neuron} una neurona es una célula nerviosa, que tiene diferentes formas, pero que se caracteriza por tener una estructura de fibras finas muy parecidas a las ramas de un árbol, llamadas dendritas, también tiene una fibra larga llamada axón. Las neuronas son responsables de transmitir y recibir información, para conseguirlo intercambian señales eléctricas a través de pequeños sitios en el cuerpo de la neurona, conocidos como sinapsis. Las neuronas reciben impulsos sensoriales del mundo exterior y son responsables de procesar estas señales para así generar una salida, que puede ser el movimiento de los músculos, pensamientos, palabras, entre otros. Pero una sola neurona no puede realizar todo este trabajo, el poder de las neuronas radica en transmitir estos impulsos sensoriales de una neurona a otra. Las neuronas están conectadas entre sí a través de los axones, las dendritas y las sinapsis. En la figura \ref{neurona} se puede apreciar la estructura de una neurona biológica.

\begin{figure}[h]
  \scalebox{0.8}{\includegraphics{img/neuron-structure.png}}
\caption[Estructura de una neurona biológica]{Estructura de una neurona biológica \cite{datos-aleatorios}.}
\label{neurona}
\end{figure}

Las neuronas y las conexiones entre ellas constituyen la clave para el procesamiento de la información \cite{neuron-2}. Las dendritas se encargan de recibir los impulsos sensoriales de otras neuronas. Estos impulsos viajan a través de los axones, que sirven como transmisores de estas señales. Los axones de una neurona están conectados a las dendritas de otra y a esta región de conexión se le llama sinapsis. Cuando hay un conjunto de neuronas conectadas entre sí, se conoce como circuito neuronal o red neuronal. Mas allá de lo teórico las conexiones e interacciones entre las neuronas de un individuo, definen como este responde a los estímulos externos, define su comportamiento, como aprende y otras conductas propias de un ser inteligente.

Al igual que los pájaros inspiraron al ser humano a volar, las redes neuronales biológicas inspiraron uno de los algoritmos más poderosos en el campo del aprendizaje automático, las redes neuronales artificiales. Como se explicará más adelante para llevar a cabo su funcionamiento las redes neuronales artificiales, tienen una serie de unidades de cómputo llamadas neuronas, que permiten a una máquina aprender de experiencias previas, a lo largo de este documento se utilizará el término redes neuronales para hacer referencia a este algoritmo. A pesar de que las redes neuronales se inspiraron en su par biológico se han vuelto bastante diferentes a estas, tanto así que muchos científicos del área han criticado que se utilice el término de red neuronal \cite{hands}, sin embargo, las redes neuronales artificiales buscan simular el funcionamiento de las redes biológicas, el mismo funcionamiento que le permite a un ser humano aprender.

\subsection{Redes Neuronales artificiales}

Como se explica en \cite{fundamentals-neural} una red neuronal es “un sistema de procesamiento de información que tiene algunas características de rendimiento en común con las redes neuronales biológicas. Fueron desarrolladas como generalizaciones de modelos matemáticos de la cognición humana o la biología neuronal”, estos sistemas de procesamiento de información permiten la resolución de problemas que no pueden ser resueltos con un enfoque tradicional. Las redes neuronales engloban una familia de algoritmos de aprendizaje supervisado, que buscan simular el comportamiento biológico de las neuronas \cite{alex}. Presentan características como la capacidad de aprender, de generalizar y de abstracción. La intención de las redes neuronales no es modelar exactamente su par biológico sino las características más relevantes.

Una red neuronal consiste de un largo número de unidades de cómputo simples llamadas neuronas, también conocidas en la literatura como unidades, células o nodos. Cada neurona está conectada a otra neurona a través de enlaces de comunicación dirigida, cada uno con un peso asociado \cite{fundamentals-neural}. Los pesos representan la información que usa la red para resolver un problema. Para comprender mejor esta idea en la figura \ref{artificial-neuron} se presenta un modelo matemático de una neurona biológica y sus elementos.

\begin{figure}[h]
  \scalebox{0.7}{\includegraphics{img/neuron.png}}
\caption{Modelo matemático de una neurona biológica.}
\label{artificial-neuron}
\end{figure}

Cada neurona recibe una serie de entradas $X=(x_1,..,x_i)$, que equivalen a las dendritas recibiendo estímulos externos en una neurona biológica, luego están las conexiones conocidas como pesos o parámetros $W=(w_1,..,w_i)$, que representan las sinapsis de su par biológico. Estos pesos son cruciales en el proceso de aprendizaje, se van ajustando en el entrenamiento de la red y a medida que esto pasa la red decide a que entradas darle más importancia. Con estas entradas y pesos se realiza una combinación lineal, que no es más que la suma ponderada de estos dos elementos, al resultado de esta combinación se le suma el sesgo $b$ quedando $\sum_{i}w_i x_i+b$, luego se aplica una función de activación $f$ que genera el resultado final $y_i$ de la neurona. Este resultado depende de cada uno de estos elementos y se puede expresar de la siguiente forma:
\[y_i=f(\sum_{i}w_i x_i+b)\]

La salida $y_i$ puede ser vista como el axón de una neurona biológica y sirve como entrada a otra neurona, las dendritas le dan importancia a dicho axón a través de las sinapsis $w_i$, dentro de la neurona se combinan las entradas con los pesos y se suma el sesgo para luego aplicar una función de activación, la salida de una neurona se puede conectar a la entrada de otra y por ello es posible conectarlas en redes \cite{alex}. Esto tiene sentido porque una sola neurona, no sería capaz de resolver problemas tan complejos como el reconocimiento del habla. El poder de las redes neuronales se encuentra en combinar estas neuronas para obtener modelos más complejos que le permitan atacar problemas de mayor envergadura.

Esta idea que se acaba de explicar del funcionamiento de una red neuronal tiene sus bases en un tipo de red neuronal artificial llamada perceptrón. Los perceptrones fueron desarrollados en las décadas de 1950 y 1960 por el científico Frank Rosenblatt, inspirado por trabajos anteriores de Warren McCulloch y Walter Pitts \cite{ml-book}. A pesar de que en su momento este algoritmo genero gran expectativa en la comunidad científica, pronto se dieron cuenta de sus debilidades, era incapaz de resolver problemas como una compuerta lógica XOR, el cual se considera un problema trivial \cite{hands}. El problema con los perceptrones estaba en que eran modelos de clasificación lineal, cada salida era lineal, por lo cual eran incapaces de aprender patrones complejos, sin embargo, los científicos lograron resolver el problema de la compuerta lógica XOR, apilando múltiples perceptrones en capas, este concepto se conoció como perceptrón multicapa \cite{hands}. Aún así, los perceptrones quedaron en el olvido, porque seguían siendo incapaces de resolver otros problemas más complejos.

Uno de los puntos claves de las redes neuronales para lograr superar las deficiencias del perceptrón y así resolver problemas de mayor envergadura, es la función de activación. Esta función lo que hace es transformar la suma ponderada mediante funciones no lineales, lo que le permite a la red utilizar efectivamente los resultados de las neuronas que la componen, hace que las redes puedan dar respuestas no lineales, convirtiéndolas en un modelo no lineal y dotándole de versatilidad, potencia y escalabilidad, lo cual hace que sean ideales para abordar problemas más complejos. En la figura \ref{activation-functions-m} se pueden observar algunas funciones de activación.

\begin{figure}[h]
  \scalebox{1.25}{\includegraphics{img/activaction-functions-m.png}}
\caption{Funciones de activación.}
\label{activation-functions-m}
\end{figure}

Como se puede entender de estas definiciones una neurona por sí sola no es capaz de resolver problemas de gran envergadura, pero configuradas en una red son capaces de realizar representaciones más complejas de los datos a partir de representaciones más simples \cite{alex}, para lograr esto las redes incluyen varias capas de neuronas que representan nuevas características de los datos, como se explicará continuación.
\subsection{Redes neuronales multicapa}

También conocidas como redes neuronales con alimentación hacia adelante, (\textit{feedforward neural network}) o perceptrón multicapa, son redes que están conformadas por múltiples capas, una capa es un término que hace referencia a una colección de neuronas. Estos modelos son llamados también con alimentación hacia adelante, porque la información fluye en una dirección, las capas están ordenadas por el orden en que reciben la señal, desde la entrada hasta la salida y están unidas en ese orden \cite{deep}. Estas redes solo tienen conexiones entre capas hacia delante. Esto último quiere decir que en este tipo configuración no existen ciclos o conexiones de retroalimentación, más adelante se explicará una extensión de estas redes, donde los ciclos de retroalimentación son posibles.

En las redes neuronales multicapa cada una de las neuronas realizan el cálculo mencionado anteriormente y propagan este resultado hacia las siguientes neuronas, hasta llegar a la capa de salida donde se calcula el resultado final de la red neuronal, es decir, el dato estimado, este paso se conoce como alimentación hacia adelante (\textit{feedforward}) \cite{alex}. Antes de llegar a la capa de salida los datos de entrada deben pasar por una serie de transformaciones en lo que se conoce como capas ocultas y mucho antes de eso, los datos de entrada son recibidos en lo que se conoce como capa de entrada, en la figura \ref{red-neuronal-m}, se presenta un ejemplo de una red neuronal, donde se señalan todos estos elementos.

\begin{figure}[h]
  \scalebox{1.3}{\includegraphics{img/red-neuronal-m.png}}
\caption{Arquitectura de una red neuronal.}
\label{red-neuronal-m}
\end{figure}

\begin{itemize}
\item Capa de entrada: Esta capa recibe los datos de entrada, sirve como un sensor a estímulos externos. Aquí no se lleva a cabo ningún mecanismo de aprendizaje, la intención de esta capa es distribuir los datos a las siguientes capas.
\item Capa de salida: Es la capa donde se forman las salidas de la red.
\item Capas ocultas: Son las capas que se encuentran entre las capas de entrada y salida, no tienen conexión directa con el exterior y son responsables de aprender características generales y específicas de los datos de entrada, gracias a eso las redes neuronales son capaces de representar más fehacientemente determinadas características del entorno que tratan de modelar \cite{modelo-computacional}.
\end{itemize}

Otro concepto clave de las redes neuronales es escoger la arquitectura de la red. La palabra arquitectura se refiere a la estructura general de la red: cuántas neuronas debería tener y cómo estas neuronas deberían conectarse entre sí \cite{deep}. En la figura \ref{red-neuronal-m}, se puede observar una arquitectura de una red neuronal de 5 capas. La cantidad de neuronas de entrada corresponde a la cantidad de variables independientes a utilizar. Por otra parte, la cantidad de capas ocultas y neuronas por capas ocultas son arbitrarias, depende de la persona que este diseñando la red y la complejidad del problema que se quiera resolver, por último, la cantidad de neuronas en la capa de salida depende de la cantidad de variables dependientes que tenga el problema. En estas arquitecturas las principales consideraciones arquitectónicas son elegir la profundidad y la cantidad de neuronas por capa \cite{deep}. Elegir la arquitectura correcta para una red neuronal, es un proceso de ensayo y error, es más un arte que una ciencia y no esta normalizado en la literatura, la experiencia es un factor determinante \cite{chollet}.
\subsection{Aprendizaje de una red neuronal}

La característica más importante de una red neuronal es la capacidad de aprender de su entorno y mejorar su rendimiento a través del aprendizaje. La manera en que las neuronas de una red neuronal están estructuradas está altamente relacionada con el algoritmo de aprendizaje, las dos técnicas principales que se utilizan para entrenar una red neuronal como la de la figura \ref{red-neuronal-m} son el algoritmo de retropropagación y el descenso del gradiente.

El proceso de aprendizaje consiste en ajustar los parámetros de la red neuronal de tal forma que la capacite para la resolución eficiente de un problema. Una red es capaz de aprender acerca de su entorno a través de un proceso iterativo de ajustes aplicados a sus pesos y sesgos, idealmente la red obtendrá mejores resultados después de cada iteración de ajuste en sus parámetros \cite{neuron-2}. Como se explicó anteriormente las redes neuronales son un tipo de algoritmo de aprendizaje supervisado, el objetivo en este tipo de aprendizaje es que los valores estimados de la red sean lo más próximo posibles a los valores observados, el aprendizaje se formula como minimizar el error entre la salida obtenida por la red y la salida deseada, lo cual se traduce a encontrar el punto mínimo de una función de error o perdida \cite{modelo-computacional}. Por ejemplo, si se quiere resolver un problema de regresión se suele utilizar como función de perdida, la suma del cuadrado de los errores, donde se calcula el cuadrado de la diferencia entre el valor observado y el valor estimado por la red \cite{alex}. Esta función de error esta definida por:
\[
E=\sum_{i=1}^N E_i=\sum_{i=1}^N \sum_{k=1}^K(y_{ik}-f_k(x_i))^2.
\]

Donde $N$ es el tamaño de la muestra, $x_i$ es un vector correspondiente al i-ésimo dato de entrenamiento, $y_{ik}$ el
vector de salidas deseadas y $f_k(x_i)$ el vector de salidas de la red. El objetivo del algoritmo de entrenamiento será minimizar esta función en función de los pesos y sesgos, es decir, se desea encontrar un conjunto de pesos y sesgos que hagan que el error sea lo más pequeño posible.

Para minimizar una función $f$ es necesario encontrar la dirección en que $f$ decrece más rápido, el concepto de derivada $f’(x)$ es útil para esto, porque indica como cambiar $x$ para hacer una pequeña mejora en la salida $y$. En el caso de una función de varias variables se debe hacer uso del vector gradiente, el cual es un vector que contiene todas las derivadas parciales de una función y es denotado por $\nabla f$ \cite{deep}. Como $E$ depende de todos los parámetros de la red, es una función de varias variables, por lo que es necesario el vector gradiente. El gradiente de esta función es igual a $\frac{\partial E}{\partial w}$, es decir, la derivada parcial de $E$ con respecto a cada uno de los parámetros de la red. El gradiente toma la dirección que determina el incremento más rápido en el error, mientras que la dirección opuesta determina el decremento más rápido. Por lo tanto, el error puede reducirse ajustando cada parámetro en la dirección opuesta al gradiente, este paso es el que se conoce como descenso del gradiente \cite{deep}.

El descenso del gradiente es un método iterativo de optimización que encuentra el mínimo de la función de perdida mediante el ajuste de los parámetros de la red neuronal \cite{hands}. Este algoritmo hace uso del vector gradiente para encontrar la dirección en que la función decrece más rápido y ajustar los parámetros según una determinada cantidad, con el fin de acercarse cada vez más a un mínimo de la función de perdida. Suponiendo que el algoritmo se encuentra en la iteración $(n + 1)$ el ajuste de los parámetros queda de la siguiente forma:
\[
w(n + 1) = w(n) -\alpha\frac{\partial E}{\partial w}
\]

Donde $\alpha$ es la tasa de aprendizaje que se usa para controlar la cantidad de ajuste de los pesos en cada paso del entrenamiento. En la figura \ref{gradient-descent} se puede observar de forma intuitiva el funcionamiento del descenso del gradiente.

\begin{figure}[h]
  \scalebox{1}{\includegraphics{img/gradient-descent.png}}
\caption[Método iterativo del descenso del gradiente]{Método iterativo del descenso del gradiente. Modificado de \cite{hands}.}
\label{gradient-descent}
\end{figure}

Para implementar el algoritmo del descenso del gradiente es necesario evaluar el modelo en todo el conjunto de datos de entrenamiento, a medida que el conjunto de entrenamiento crece, el tiempo y el costo computacional para ajustar los parámetros en una sola iteración, se vuelven extremadamente largo y costoso \cite{deep}. Realmente en la práctica se toman aleatoriamente un pequeño número de ejemplos del conjunto de datos de entrenamiento, este conjunto más pequeño se conoce como lote (\textit{batch}) y con este se calcula el error promedio, para obtener el gradiente y ajustar los pesos, este enfoque logra mejores tiempos de entrenamiento y menos costo computacional, esta variación del descenso del gradiente se conoce como \textit{mini-batch gradient descent} \cite{hands} y está basada en el gradiente estocástico, esta última variación toma aleatoriamente un solo ejemplo de los datos de entrenamiento, para enseguida ajustar los pesos sin realizar ningún promedio del error.

Como se viene explicando el aprendizaje en las redes neuronales requiere calcular el vector gradiente de la función de perdida, estas funciones son bastante complejas porque dependen de cada uno de los parámetros de la red, calcular el gradiente es una tarea muy exigente, por eso se introduce otro algoritmo al proceso de aprendizaje para facilitar este cálculo. Este algoritmo se conoce como retropropagación (\textit{backpropagation}), es capaz de calcular el gradiente de la función de error, con respecto a cada parámetro de la red de una manera muy eficiente.

El algoritmo de retropropagacion también conocido como regla delta generalizada, permite que la información del error fluya hacia atrás a través de la red, para calcular el gradiente \cite{deep}. Intuitivamente consigue que tan responsable son cada uno de los parámetros de la red por parte del error, para luego ajustarlos con el algoritmo del gradiente del descenso \cite{hands}. Para conseguir esto este algoritmo usa la regla de la cadena con un orden específico de operaciones, que es altamente eficiente para calcular las derivadas parciales de la función de error y obtener el vector gradiente de las capas ocultas \cite{deep}.

Para resumir y como se explica en \cite{hands}, el proceso de aprendizaje de una red neuronal consta de los siguientes puntos:

\begin{itemize}
\item Se extrae un lote de los datos de entrenamiento, este lote sirve de entrada a la red neuronal para calcular la salida, es decir, los datos estimados, este punto se conoce como alimentación hacia adelante.
\item Con los datos estimados se calcula el error de la red, se utiliza una función de perdida que compara los valores observados con los valores estimados.
\item Luego con el algoritmo de retropropagación se calcula el vector gradiente, para saber cuánto contribuyo cada parámetro al error final, utilizando la regla de la cadena y propagando el error hacia atrás, hasta llegar a la capa de entrada.
\item Finalmente, se utiliza el algoritmo del descenso del gradiente para ajustar los parámetros de la red, utilizando los gradientes calculados.
\end{itemize}

Por último, en el proceso de aprendizaje no se busca encontrar un mínimo global de la función de perdida, debido a que esto puede resultar en un sobreajuste de los parámetros a los datos de entrenamiento, por eso se tienen condiciones de parada para detener el entrenamiento, por ejemplo, que el error descienda por debajo de un valor establecido o que se hayan cumplido cierta cantidad de iteraciones sobre todo el conjunto de datos de entrenamiento. A estas iteraciones se le conoce como epochs \cite{chollet}.

Las redes neuronales son de extrema importancia para los investigadores del aprendizaje automático, estas redes forman la base de muchas aplicaciones comerciales importantes en la actualidad, y son las bases teóricas del aprendizaje profundo.




