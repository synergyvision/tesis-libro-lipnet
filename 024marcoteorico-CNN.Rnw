% !Rnw root = 000proyecto.Rnw

<<echo=FALSE>>=
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(gridExtra)
@

\section{Visión por Computadora}

La visión por computadora, es una rama de las ciencias de la computación, que abarca una amplia variedad de técnicas de procesamiento de imágenes con el fin de extraer información de interés de estas. Este campo busca diseñar algoritmos para extraer la información que hay en una imagen o vídeo de forma automatizada. Como se explica en \cite{dl-cv}, el objetivo es desarrollar técnicas que imiten las habilidades visuales humanas en una computadora. Esta rama de la computación intenta describir las imágenes, reconstruir sus propiedades, como la forma, la iluminación, la distribución de colores, entre otras características.

La visión por computadora se está utilizando hoy en una amplia variedad de aplicaciones del mundo real como:

\begin{itemize}
\item Reconocimiento de objetos.
\item Clasificación de imágenes.
\item Detección e identificación de rostros.
\item Estimación de posturas.
\item Detección de eventos.
\end{itemize}

Esta rama tiene más de 50 años de investigación, nació en 1960 y se desarrolló a la par de la computación, en un principio se pensó que en muy poco tiempo se iban a tener computadoras capaces de interpretar las imágenes como lo hacen los seres humanos \cite{alex}. Los científicos desarrollaron técnicas utilizando conceptos de campos como las matemáticas, física, estadísticas logrando atacar muchos de los problemas de la visión por computadora, pero no fue hasta el surgimiento del aprendizaje profundo y en especial las redes neuronales convolucionales, que se lograron resultados realmente notables, superando los métodos existentes e incluso superando a seres humanos, en problemas como la clasificación de imágenes.

El aprendizaje profundo, permite la extracción de la información contenida en una imagen de forma automatizada, la visión por computadora ha sido tradicionalmente una de las áreas de investigación más activa para aplicaciones de aprendizaje profundo, estas aplicaciones utilizan redes neuronales profundas para el reconocimiento de objetos, esto incluye identificar que objeto está presente en la imagen, segmentación de objetos, es decir, anotar una imagen con cuadros delimitadores alrededor de cada objeto, transcribir una secuencia de símbolos que se encuentren en una imagen o etiquetar cada pixel en una imagen con la identidad del objeto al que pertenece \cite{deep}.

Este auge de utilizar el aprendizaje profundo en problemas relacionados con la visión por computadora es relativamente reciente, se debe al aumento en el poder computacional y la cantidad masiva de datos de entrenamiento disponibles, millones de imágenes y vídeos son subidos todos los días al internet en especial a las redes sociales, gracias a esta masiva cantidad de datos, los científicos dedicados a la inteligencia artificial han logrado crear conjuntos de datos de entrenamiento, que colocan a disposición de toda la comunidad científica. \textit{ImageNet} es uno de los conjuntos de datos más populares, con más de 14 millones de imágenes, investigadores, estudiantes y todo aquel interesado en la clasificación de imágenes puede utilizar estos datos para entrenar sus modelos de aprendizaje profundo.

Las imágenes son el mayor punto de interés en los problemas que trata la visión por computadora, a continuación, se explicará que es una imagen y los elementos que la componen.

\subsection{Imagen digital}

Una imagen es la representación visual de algún objeto, una imagen digital es la representación bidimensional de una imagen real capturada por algún medio electrónico y que es representada mediante píxeles \cite{modelo-computacional}. Cada imagen consta de un conjunto de píxeles. Los píxeles representan un punto indivisible en la pantalla \cite{alex}. Un píxel se considera el “color” o la “intensidad” de la luz que aparece en un determinado lugar en la imagen. Si se representa una imagen como una matriz, cada posición contiene un pixel.

Como se explica en \cite{dl-python} la mayoría de los píxeles son representados en dos formas: escala de grises y a color.

En una imagen en escala de grises, cada pixel tiene un valor entre 0 y 255, donde cero corresponde a negro y 255 a blanco. Los píxeles a color se representan en el espacio de color RGB (Rojo, Verde, Azul) por sus siglas en inglés (\textit{Red, Green, Blue}). A diferencia de la representación en escala de grises en este espacio de color, los píxeles están representados por una lista de tres valores: un valor para el componente rojo, uno para el verde y otro para el azul \cite{dl-python}. Para representar un color se define la cantidad de rojo, verde y azul contenido en un solo píxel. Cada canal rojo, verde y azul puede tener un valor entre 0 y 255. En la figura \ref{color-image} se puede apreciar una representación de una imagen digital en el espacio de color RGB, donde cada matriz representa la intensidad del rojo, verde y azul en cada pixel.

\begin{figure}[h]
  \scalebox{0.8}{\includegraphics{img/color-channels.png}}
\caption{Características de una imagen digital}
\label{color-image}
\end{figure}

Como se puede observar en esta figura \ref{color-image}, una imagen se puede representar como una matriz multidimensional, donde las columnas representan el ancho y las filas el alto de la imagen, también hay que tener en cuenta una tercera dimensión que representa los canales de colores o profundidad del color, lo cual indica si la imagen se encuentra en una escala de grises o a color. En la visión por computadora los dos problemas principales que se deben resolver para el procesamiento de imágenes son:  reducción de la dimensión y extracción de características, se debe aliviar la carga computacional del procesamiento de imágenes mediante la reducción de la dimensión de estas, a su vez se debe extraer información de interés de la imagen no importa en donde se encuentre. Las redes neuronales convolucionales se crearon para resolver estos problemas.

\section{Redes Neuronales Convolucionales}

Como se explica en \cite{hands} a finales de los años 50 los científicos David H. Hubel y Torsten Wiesel, hicieron una serie de experimentos en animales, lo cual les dio un gran entendimiento de la estructura de la corteza visual. Demostraron que las neuronas en la corteza visual tienen un pequeño campo receptivo local, lo que significa que estas neuronas solo reaccionan a estímulos visuales, también demostraron que algunas neuronas solo respondían a estímulos específicos, como imágenes con líneas horizontales y otras solo a imágenes con líneas verticales, además notaron que algunas neuronas tenían campos receptivos más grandes, lo que les permitía reaccionar a patrones más complejos que eran combinación de patrones más simples. Estas observaciones llevaron a la idea de que las neuronas con un campo receptivo más grande, se basaban en los patrones más simples capturados por neuronas vecinas. Todos estos estudios inspiraron la creación del neocognitron que luego evolucionó a lo que hoy se conoce como redes neuronales convolucionales.

Así como las redes neuronales se inspiraron en como funciona el cerebro para llevar a cabo su funcionamiento interno, las redes neuronales convolucionales hicieron algo similar, se inspiraron en el funcionamiento de la corteza visual, para detectar características, asociar las mismas y reconocer una imagen. También conocidas como redes convolucionales o CNN por sus siglas en inglés (\textit{Convolutional Neural Network}), fueron introducidas por Lecun et al en \cite{Lecun-Net}, son un tipo de red neuronal que se especializa en procesar datos que vienen en forma de matriz, por ejemplo, imágenes, su nombre se debe a que implementan una operación matemática llamada convolución, una red convolucional se caracteriza por utilizar esta operación en al menos una de sus capas \cite{deep}.

Estas redes están compuestas por una serie de capas sucesivas las cuales se encargan de extraer y  aprender características complejas, lo primero que hacen es aplicar una capa de convolución a los datos de entrada, luego aplican una función de activación sobre los resultados de estas convoluciones, también utilizan otro tipo de operación conocida como \textit{pooling}, para reducir el alto y el ancho de la imagen, utilizan estos tres elementos sucesivamente para crear diferentes arquitecturas, hasta que finalmente en la capa de salida aplican una red neuronal multicapa con alimentación hacia adelante, para obtener el resultado final de la red.

Los bloques principales de construcción de una red convolucional son entonces la capa de convolución y la capa de \textit{pooling}, estas dos capas se utilizan para diseñar arquitecturas cada vez más profundas para resolver problemas de procesamiento de imágenes cada vez más complejos \cite{alex} a continuación se definirán estas capas y sus características principales.

\subsection{Capa de Convolución}

La capa de convolución es la capa más importante de las redes neuronales convolucionales, esta capa se encarga de aprender patrones locales, encontrados en pequeñas partes de la imagen de entrada. Las neuronas de la primera capa están conectadas solamente a los pixeles de un campo receptivo rectangular de la imagen de entrada, en la segunda capa las neuronas están conectadas a un pequeño rectángulo de la primera capa \cite{hands}. Esta configuración permite que la red se concentre en aprender características más generales en la primera capa oculta, para luego aprender características más específicas en las siguientes capas y así poder reconocer imágenes y patrones complejos.

Como se explica en \cite{chollet} la característica de aprender patrones locales, le da a la red convolucional dos propiedades interesantes:

\begin{itemize}
\item Los patrones que aprenden son invariantes. Esto quiere decir que después de aprender un patrón, por ejemplo, en la esquina inferior izquierda de la imagen, la red convolucional es capaz de reconocer ese mismo patrón en cualquier otro lugar. Esto hace que estas redes sean muy eficientes al procesar imágenes, porque no siempre el objeto que se desea clasificar, segmentar o reconocer se encuentra en la misma posición, el mismo tamaño o en la misma escala.
\item Pueden aprender jerarquías espaciales de patrones, igual que con las redes neuronales multicapa, en las redes convolucionales, las primeras capas de convolución pueden aprender a reconocer bordes, contornos, líneas, mientras que las capas posteriores aprenden patrones más complejos a partir de estos patrones más simples, aprendiendo así una jerarquía de conceptos.
\end{itemize}

El campo receptivo de las redes convolucionales también conocido como kernel o matriz de convolución, es utilizado en la capa de convolución para extraer características e información relevante de los datos de entrada, extraen características simples que luego se componen en más complejas \cite{alex}. Como se explicó anteriormente una imagen es representada como una matriz multidimensional, un kernel también es representado como una matriz de valores, es más pequeña comparada a la imagen de entrada, se usa para desenfocar, enfocar, detectar bordes y otras funciones de procesamiento de imágenes \cite{dl-python}. Los kernels sirven como filtros que resaltan características, como contornos o esquinas, se especializan en encontrar las mismas características no importa en qué lugar de la imagen se encuentren, en la figura \ref{kernel-app} se puede observar el efecto de aplicar diferentes kernels sobre una imagen.

\begin{figure}[h]
  \scalebox{1}{\includegraphics{img/kernel-app.png}}
\caption{Efecto de diferentes kernels}
\label{kernel-app}
\end{figure}

Intuitivamente el kernel se coloca en la parte superior de la imagen de entrada y se desliza de izquierda a derecha y de arriba a abajo, aplicando la operación de convolución. Esta operación, consiste en realizar el producto componente por componente entre dos matrices, seguido de la suma de todos los componentes de este resultado \cite{dl-python}. En este caso las dos matrices vendrían a ser el kernel y los pixeles de la región de la imagen, sobre la cual se encuentra el kernel en ese momento. En la figura \ref{conv} se puede apreciar la operación de convolución y el recorrido que realiza el kernel.

\begin{figure}[h]
  \scalebox{1}{\includegraphics{img/convolution.png}}
\caption{Convolución}
\label{conv}
\end{figure}

Los valores correspondientes al kernel representan los parámetros de la red convolucional, solo que están agrupados en matrices, se ajustan automáticamente para aprender características de los datos de entrenamiento, mediante un proceso similar a la retropropagación de las redes neuronales multicapa \cite{alex}.

Como se observa en la figura \ref{conv}, al aplicar el kernel a los datos de entrada se genera lo que se conoce como un mapa de características, aquí se resaltan las áreas de una imagen que más activaron al kernel \cite{hands}, cada mapa de características está conformado por las neuronas de la red convolucional. Los mapas de características son el resultado de aplicar la capa de convolución sobre la entrada, cada neurona de un mapa de características comparte los mismos parámetros (kernel), este concepto fue introducido por Lecun \cite{Lecun-Net} y se conoce como \textit{shared weigths}, esta propiedad es importante porque reduce la complejidad del cálculo y la cantidad de parámetros, reduciendo así la capacidad de la red, evitando el sobreajuste de la misma.

Una capa de convolución está conformada por múltiples kernels, cada uno aprendiendo patrones diferentes de los datos de entrada y generando múltiples mapas de características, se generan tantos mapas de características como kernels se definan en la capa. En la capa de convolución se deciden la cantidad de kernels, el tamaño del kernel, por lo general son matrices cuadradas de $3x3$, $5x5$ o $7x7$, el desplazamiento, es decir, si el kernel se va a deslizar de $1$ en $1$ o $2$ en $2$ y finalmente se escoge el relleno. Esto último se refiere a que cuando se aplica la capa convolución a los datos de entrada, la dimensión de estos se reduce, perdiendo información de los bordes, si es necesario mantener esta información se pueden rellenar los bordes de la entrada con ceros, de tal manera que al aplicar la capa de convolución se mantenga el mismo tamaño de los datos. Todos estos valores que se deciden en la capa de convolución se denominan hiperparámetros \cite{alex}. En la figura \ref{features-maps} se pueden apreciar los mapas de características al aplicar una de capa convolución.

\begin{figure}[h]
  \scalebox{1}{\includegraphics{img/feature-maps.png}}
\caption{Mapas de características.}
\label{features-maps}
\end{figure}

Durante el proceso de entrenamiento, la capa de convolución aprenderá automáticamente los kernels más útiles para el problema que está intentando resolver, estos kernels serán más eficaces en la generación de nuevos mapas de características, los cuales servirán de entrada a las siguientes capas ocultas que aprenderán a reconocer características más específicas.

Después de aplicar una capa convolución, se aplica una función de activación como la sigmoide o RELU a los mapas de características resultantes, esto se hace con la finalidad de aumentar la no linealidad de la red. Cuando se aplica una capa de convolución se corre el riesgo de introducir linealidad a los datos, para romper esta linealidad se aplican funciones de activación al igual que en las redes neuronales.

Los mapas de características sirven de entrada a la siguiente capa de convolución o una capa de \textit{pooling}, esta última es la segunda pieza más importante de una red convolucional, sirve para reducir la dimensión de los datos como se explicará a continuación.

\subsection{Capa de pooling}

Un problema que tienen las redes convolucionales, es que en las capas de convolución se requiere una gran cantidad de memoria RAM para conservar los valores que se hayan calculado en el paso de alimentación hacia adelante \cite{hands}, también pueden llegar a tener una cantidad exorbitante de parámetros, que se deben ajustar para que la red haga predicciones precisas, esto tiene como consecuencia una gran carga computacional y mayor tiempo de entrenamiento. La capa de \textit{pooling} o sub muestraje, se encarga de atacar estos problemas, reduce la dimensión de los datos de entrada para aligerar la carga computacional, disminuir el tiempo de entrenamiento, reducir la cantidad de memoria y reducir la cantidad de parámetros de la red, lo cual último ayuda también a que la red no se sobreajuste a los datos de entrenamiento \cite{dl-python}.

La función principal de la capa de \textit{pooling} es reducir el ancho y el alto de los datos de entrada, al conseguirlo se reduce la cantidad de parámetros lo que ayuda a disminuir el riesgo de sobreajuste del modelo.

Al igual que en la capa de convolución, las neuronas en la capa de \textit{pooling} están conectadas a las neuronas de las capas anteriores ubicadas en un pequeño campo receptivo rectangular. En esta capa también se debe escoger el tamaño de esta ventana o campo receptor, el desplazamiento y el relleno, pero a diferencia de la capa de convolución, en la capa de \textit{pooling} no sucede ningún tipo de aprendizaje, es decir, no se ajusta ningún parámetro debido a que esta capa no posee ninguno \cite{hands}, lo que se realiza es una operación fija entre los datos de entrada y el campo receptor.

Se realiza el mismo barrido que en la capa de convolución, el campo receptor se sitúa en la parte superior izquierda de los mapas de características y se desliza de izquierda a derecha y de arriba abajo, y se toma un valor que represente la información que se encuentre en el campo receptor, se utiliza una operación que genera un valor representativo de cada campo receptor y se elimina el resto de la información \cite{alex}.

Un ejemplo de una capa de \textit{pooling} se puede observar en la figura \ref{pooling}.

\begin{figure}[h]
  \scalebox{1}{\includegraphics{img/pooling.png}}
\caption{Capa de pooling}
\label{pooling}
\end{figure}

Como se aprecia en la figura \ref{pooling}, las dos formas principales para realizar la reducción de la dimensión son: el \textit{max pooling} y el \textit{average pooling}. El \textit{max pooling} consiste en tomar sólo el valor máximo del campo receptor, mientras que en el \textit{average pooling} se calcula el promedio de los valores, solo el máximo o el promedio pasan a la siguiente capa, los demás valores se descartan \cite{alex}.

El \textit{max pooling} por lo general se aplica después de una capa de convolución mientras que el \textit{average pooling} se aplica hacia el final de la red convolucional. El \textit{max pooling} es la operación de \textit{pooling} más popular, usualmente es implementado con campos receptores de $2x2$ y un desplazamiento de $2$, para reducir en un factor de $2$ los datos de entrada \cite{dl-python}. La capa de \textit{pooling} se aplica a la profundidad de los datos de entrada, es decir, a cada uno de los mapas de características después de una capa de convolución o a los canales de colores si la entrada es una imagen.

Además de reducir la dimensión, la capa de pooling también introduce invarianza a pequeñas traslaciones, esto quiere decir que no importa en que parte de la imagen se encuentren los patrones a reconocer, la red convolucional va a ser capaz de reconocerlos, esta propiedad es útil cuando se desea saber si una característica está presente en la imagen \cite{deep}.

\subsection{Arquitectura de las redes neuronales convolucionales}

Otro bloque de construcción importante en la arquitectura de una red convolucional son las redes completamente conectadas, estas redes ya se explicaron anteriormente, simplemente son redes neuronales con alimentación hacia adelante que se utilizan hacia el final de la red convolucional.

La arquitectura de una red convolucional consiste en combinar las capas de convolución y \textit{pooling} y así extraer características e información relevante, para luego alimentar a una red neuronal completamente conectada y obtener el resultado final. Las capas de convolución y la red neuronal completamente conectada son las únicas que pasan por un proceso de aprendizaje, la capa de \textit{pooling} solo se encarga de realizar una operación fija. Las arquitecturas más comunes se componen combinando sucesivamente una capa de convolución seguida de una capa de pooling, se repiten estas dos capas hasta que la entrada pasa a una red neuronal completamente conectada.

A lo largo de los años se han desarrollado variantes de esta arquitectura fundamental, lo que ha traído como resultado grandes avances en el campo de la visión por computadora. Las redes neuronales convolucionales han sido muy importantes para el desarrollo del aprendizaje profundo, fueron los primeros modelos en tener un buen rendimiento y resolver problemas del mundo real, incluso antes de que el aprendizaje profundo se considerara viable, estas redes llevaron a la aceptacion de las redes neuronales en general y siguen liderando la investigacion de las aplicaciones del aprendizaje profundo \cite{deep}. Las redes convolucionales se especializan en el procesamiento de imágenes, en investigaciones más recientes, se ha estudiado el uso de una red convolucional especial llamada red convolucional 3D para el procesamiento de vídeos, a continuación se definirá su funcionamiento.

