% !Rnw root = 000proyecto.Rnw

<<echo=FALSE>>=
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(gridExtra)
@

\newpage

\chapter{Marco teórico}
Este capítulo tiene como finalidad presentar las bases teóricas que fundamentan el desarrollo del proyecto y definir los conceptos para el correcto entendimiento de los siguientes capítulos, donde se describen las actividades que se llevaron a cabo durante la investigación. El capítulo constará de una serie de definiciones del mundo de la inteligencia artificial, empezando por el aprendizaje automático, definiendo que son las redes neuronales y finalmente en que consiste el reconocimiento del habla en vídeos.

\section{Aprendizaje  automático}

El aprendizaje automático mejor conocido como \textit{Machine Learning} es un concepto que ha tomado gran relevancia en la actualidad y que se escucha cada vez con mayor frecuencia en áreas como la ciencia, la tecnología, medicina y finanzas. Ha logrado resolver problemas como:
\begin{itemize}
\item Predecir si un paciente sufrirá una enfermedad basados en sus datos demográficos y los resultados de exámenes.
\item Reconocer objetos o patrones visuales en imágenes.
\item Realizar traducciones de texto.
\item Generar subtítulos de forma automatizada en un vídeo.
\item Programar agentes automatizados e interactivos para ofrecer ayuda a los clientes.
\item Predecir el desempeño de una empresa basados en sus indicadores económicos.
\end{itemize}

A pesar de ser un concepto que ha ganado mucha popularidad en la actualidad sus orígenes se remontan a los años 50. En el año 1959, Samuel \cite{samuel}, define el concepto de aprendizaje automático como “el campo de estudio que da a las computadoras la habilidad de aprender sin ser explícitamente programadas”. Otra definición a la que se hace bastante referencia en la literatura y más orientada a la ingeniería fue elaborada por Mitchell \cite{mitchell}, quien lo definió de la siguiente manera, “Se dice que un programa de computadora aprende de la experiencia \textit{E} con respecto a alguna tarea \textit{T} y alguna medida de rendimiento \textit{P}, si su rendimiento en \textit{T}, medido por \textit{P}, mejora con la experiencia \textit{E}”. El aprendizaje automático, es la ciencia de programar computadoras para que puedan aprender de los datos y resolver problemas para los cuales no fueron explícitamente programados.

Este enfoque permite abordar problemas que son muy difíciles de resolver con programas escritos y diseñados con un enfoque tradicional, por ejemplo, resolver el problema de traducir un idioma a otro, se podría realizar escribiendo un conjunto de instrucciones que procese el texto a traducir, sin embargo, a medida que se va realizando el programa este crece en complejidad y su desempeño en la tarea es bastante pobre. Al utilizar el aprendizaje automático se implementaría un modelo que aprenda a traducir idiomas, este enfoque permite no tener instrucciones en el programa que explícitamente se encarguen de traducir un idioma a otro, sino tener un programa que aprenda a realizar esta tarea, este tipo de algoritmos son mucho más escalables por que aprenden patrones que se encuentran en los datos.

Un algoritmo de \textit{machine learning} es entrenado con muchos ejemplos relevantes para realizar una tarea, encuentra una estructura estadística en estos ejemplos que le permiten aprender patrones para automatizar la tarea. Esta área de estudio está altamente relacionada con la estadística, pero a diferencia de esta el \textit{machine learning} tiende a tratar con conjuntos de datos muy grandes \cite{chollet}. El \textit{machine learning} involucra los siguientes puntos:
\begin{itemize}
\item Datos de entrada.
\item Datos observados.
\item Medida de rendiemiento.
\end{itemize}

Un algoritmo de \textit{machine learning} consiste en transformar los datos de entrada en salidas que tienen una gran relevancia para resolver una tarea, estas salidas se conocen como datos estimados, luego de que se obtienen estos datos, se evalúan contra los datos observados utilizando una medida de rendiemiento, esta medida se utiliza para calcular el error o distancia entre los datos observados y los datos estimados y así entender que tan bien está realizando la tarea el algoritmo. En base a la medida de rendiemiento se ajusta el funcionamiento del algoritmo, con el fin de minimizar la distancia entre los valores observados y estimados y así minimizar el error \cite{chollet}. Este proceso se conoce como entrenamiento y permite al algoritmo aprender patrones, encontrar características e información relevante a la tarea, para realizar estimaciones cada vez más cercanas a los datos observados. Un modelo de \textit{machine learning} parte de un conjunto de datos que contienen información sobre un problema que se desea resolver, realiza un ciclo de estimación y cálculo del error para ajustar el funcionamiento del modelo, minimizar el error y así inferir sobre datos nuevos \cite{alex}. El aprendizaje de un algoritmo de \textit{machine learning} se puede interpretar como el ajuste de los parámetros del algoritmo, este ajuste se debe al proceso de entrenamiento, que mediante la optimización de una función que minimiza el error, ajusta el funcionamiento del algoritmo automáticamente, permitiendole realizar mejores inferencias sobre datos nuevos.

Cuando se realiza un modelo de \textit{machine learning}, es más importante el desempeño que tenga en datos que nunca ha visto antes, ya que esto determinará que tan bien funcionará el algoritmo cuando sea desplegado en el mundo real \cite{deep}, por lo tanto, los datos de entrada se dividen en dos conjuntos, el conjunto de datos de entrenamiento y el conjunto de datos de prueba. El conjunto de datos de entrenamiento, se utiliza para entrenar el algoritmo en la tarea que se desea resolver y ajustar el funcionamiento del mismo para que realice estimaciones cada vez mejores \cite{alex}. El conjunto de datos de prueba es independiente de los datos utilizados para entrenar el modelo y sirve para medir el rendimiento en datos nunca antes vistos, se utiliza la misma medida de rendimiento que se utilizó en el proceso de entranamiento.

El reto principal del \textit{machine learning}, es tener un buen rendimiento no solo en los datos con los que se entrenó el modelo, sino también en datos nunca antes vistos. Esta capacidad de tener un buen rendimiento en datos no observados antes, se llama generalización \cite{deep}. A la hora de entrenar un modelo de \textit{machine learning}, la generalización se puede ver perjudicada por dos factores: el sobreajuste (\textit{overfitting}) y subajuste (\textit{underfitting}). El subajuste sucede cuando el modelo no tiene la capacidad de siquiera tener buenos resultados en los datos de entrenamiento, por lo tanto, es incapaz de generalizar bien en datos nunca antes vistos. El sobreajuste sucede cuando los parámetros del algoritmo se ajustan demasiado a los datos de entrenamiento, un modelo sobreajustado tiene un buen rendimiento en los datos de entrenamiento, pero un rendimiento bastante pobre en los datos de prueba o en datos que no ha visto antes. En el proceso de aprendizaje de un algoritmo de \textit{machine learning}, se utilizan las características conocidas de los datos. Todas estas características proporcionan información para que el modelo estime, calcule el error, realice el ajuste y minimice el error \cite{alex}. Todo este proceso se debe realizar teniendo cuidado de no sobreajustar o subajustar el modelo, de modo que tenga un buen rendimiento y pueda generalizar mejor.

Como se ha venido explicando un algoritmo de \textit{machine learning} pasa por un proceso de aprendizaje para poder resolver un problema, existen diferentes técnicas de aprendizaje las cuales se dividen en:
\begin{itemize}
	\item Aprendizaje supervisado.
	\item Aprendizaje no supervisado.
\end{itemize}

\subsection{Aprendizaje supervisado}
En este enfoque los datos de entrenamiento están asociados a un objetivo o etiqueta, esta etiqueta representa el valor de la característica que se desea predecir, por ejemplo, si se quisiera clasificar si una imagen es un perro o un gato, cada imagen del conjunto de imágenes de entrenamiento, vendría etiquetada con una de estas dos clases. El término aprendizaje supervisado se origina porque la etiqueta es provista por un instructor o maestro, que le enseña al modelo de \textit{machine learning} el resultado de la tarea que debe realizar \cite{deep}. Un problema clásico del aprendizaje supervisado es la clasificación, como el ejemplo de clasificar si una imagen es un perro o un gato. Otro problema típico que se puede resolver con esta técnica es inferir un valor numérico, como el precio de un inmueble basados en distintas características (antigüedad, zona, cantidad de habitaciones), este tipo de problemas se conoce como regresión \cite{hands}. Entre las técnicas más populares de aprendizaje supervisado se encuentran la regresión lineal, regresión logística, máquina de vectores de soporte, arboles de decisión, arboles aleatorios y redes neuronales \cite{hands}. Este documento se centra en la aplicación de las redes neuronales, el corazón del aprendizaje profundo, se definirá más adelante como pueden ser utilizadas para abordar problemas como la visión por computadora y el procesamiento del lenguaje natural dos de las técnicas principales para la lectura de labios.

\subsection{Aprendizaje no supervisado}
A diferencia del aprendizaje supervisado, esta técnica no necesita que los datos de entrenamiento estén previamente asociados a una etiqueta, es decir, no necesitan del conjunto de datos observados para ajustar los parámetros del modelo, debido a la falta de estos datos objetivos que cumplen el papel de un maestro en el aprendizaje supervisado a esta técnica se le conoce como aprendizaje no supervisado \cite{statical-learning}. Este enfoque se encarga de aprender características útiles de la estructura del conjunto de datos \cite{deep}, se utiliza para comprender mejor las correlaciones que existen en los datos, para la visualización y la compresión de los mismos.

Algunas de las técnicas más populares de este enfoque son el clustering, la detención de anomalías y la reducción de la dimensionalidad. Por ejemplo, si se tuviera un conjunto de datos conformados por los usuarios de un sitio web, se podría utilizar la técnica de clustering para identificar patrones y agrupar a estos usuarios en grupos separables \cite{hands}. Otro de los usos que se le da este enfoque es la reducción de la dimensionalidad, lo cual consiste en simplificar el conjunto de datos sin perder información relevante al problema. Esta última técnica es a menudo combinada con un modelo de aprendizaje supervisado con el fin de entrenar más rápido, reducir el espacio en memoria e incluso obtener mejores resultados \cite{hands}.

Cabe destacar que estos son solo algunos de los algoritmos que existen en el campo del \textit{machine learning}, estas técnicas de aprendizaje han tomado gran relevancia en los últimos años, por la creciente cantidad de conjuntos de datos y el excelente rendimiento que tienen en problemas de clasificación, regresión, clustering entre otros. El aprendizaje supervisado es por lejos la forma dominante de aprendizaje profundo, con una gran variedad de aplicaciones en el mundo real \cite{chollet}. Al final todos estos enfoques de aprendizaje proporcionan técnicas para desarrollar programas que resuelven un problema sin ser explícitamente programados para ello, a través del entrenamiento sobre un conjunto de datos, donde se calcula un error y se ajustan los parámetros de un modelo.







